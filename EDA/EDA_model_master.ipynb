{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# This notebook will serve the EDA for the cleaned dataset that we used for modeling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Libraries and loading CSV"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Import necassary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Setup axis for plots\n",
    "sns.set_context(\"talk\", font_scale=1.5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# load dataset\n",
    "df_master = pd.read_csv('../data/super_master.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# First look at the dataset\n",
    "df_master.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Remove unnecassary columns and show shape of dataframe"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Remove unnecassary unnamed columns\n",
    "df_master.drop(['Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0_x', 'Unnamed: 0_y'], axis=1, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Shape of the dataset\n",
    "print('The dataset contains %s oberservations and %s features' %(df_master.shape[0], df_master.shape[1]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Convert date features in the right data type and show first description"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Convert column arrival_date to datetime\n",
    "df_master['arrival_date'] = pd.to_datetime(df_master['arrival_date'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# First description of the numerical features\n",
    "round(df_master.describe(),3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Number of properties and filtering for year 2019"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Number of unique properties, the included years and months\n",
    "print('Number of unique properties:', df_master.listing_id.nunique())\n",
    "print('The included years are', df_master.year.unique())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Number of oberservations per year\n",
    "print(df_master.query('year == 2019').shape[0])\n",
    "print(df_master.query('year == 2019').shape[0] / df_master.shape[0] * 100)\n",
    "print(df_master.query('year == 2020').shape[0])\n",
    "print(df_master.query('year == 2020').shape[0] / df_master.shape[0] * 100)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The dataset included inquiries from the years 2019 and 2020. We have the data from 17,185 different properties. Of a total of 6,081,983 observations, 1,881,180 observations are from 2019 (30.9%) and 4,200,803 observations are from 2020 (69.1%).\n",
    "\n",
    "Due to the influence of the corona pandemic on the inquiries 2020 (as we colud see in the EDA inquiries), we are focussing on the year 2019. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Filter dataset for year 2019\n",
    "df_master_2019 = df_master.query('year == 2019')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Save Master 2019 as csv\n",
    "df_master_2019.to_csv('../data/super_master_2019.csv')\n",
    "\n",
    "# Import Master 2019\n",
    "#df_master_2019 = pd.read_csv('../data/super_master_2019.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Number of unique properties in year 2019\n",
    "print('Number of unique properties in the year 2019:', df_master_2019.listing_id.nunique())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The dataset includes 1,881,180 inquiries for 17,000 different properties in the year 2019."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Grouping / Clustering features by inquiry rate "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. We will define three categories of inquiry rate: low, middle, high. Inquiry rate was calculated by expose views and inquiry count. Let's see the distribution of inquiry rate."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Boxplot inquiry rate\n",
    "ax = sns.boxplot(x=df_master_2019[\"inquiry_rate\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Inquiry rate per month\n",
    "ax = sns.boxplot(x=\"month\", y=\"inquiry_rate\", data=df_master_2019)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We define the category \"low\" as the lowest 25% inquiry rates, the category \"high\" as the highest 25% inquiry rates and the category \"middle\" as the inquiry rates between the lowest and highest group."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Calculate inquiry_rate for quartiles to define categorical groups\n",
    "print(df_master_2019.inquiry_rate.describe())\n",
    "print(df_master_2019.inquiry_rate.quantile(.25))\n",
    "print(df_master_2019.inquiry_rate.quantile(.75))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create new column with the categories for inquiry rate\n",
    "\n",
    "# Create a list of our conditions\n",
    "conditions = [\n",
    "    (df_master_2019['inquiry_rate'] <= df_master_2019.inquiry_rate.quantile(.25)),\n",
    "    (df_master_2019['inquiry_rate'] > df_master_2019.inquiry_rate.quantile(.25)) & (df_master_2019['inquiry_rate'] < df_master_2019.inquiry_rate.quantile(.75)),\n",
    "    (df_master_2019['inquiry_rate'] >= df_master_2019.inquiry_rate.quantile(.75))\n",
    "]\n",
    "\n",
    "# create a list of the values we want to assign for each condition\n",
    "values = ['low', 'middle', 'high']\n",
    "\n",
    "# create a new column and use np.select to assign values to it using our lists as arguments\n",
    "df_master_2019['cat_inquiry_rate'] = np.select(conditions, values)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Group features by category inquiry rate"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Correlations between some features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# generate the heatmap\n",
    "corr = df_master.corr()\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "sns.heatmap(\n",
    "    corr,\n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True\n",
    ")\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ");"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Generate table with correlations \n",
    "df_master.corr().style.background_gradient(cmap='coolwarm')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('.venv': venv)"
  },
  "interpreter": {
   "hash": "7033859b39016b1cbb0cfa821a6f288e7fd907fe4b33f32f92dbeb273ada45c0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}