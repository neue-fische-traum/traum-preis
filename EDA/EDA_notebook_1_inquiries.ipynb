{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('3.8.5')"
  },
  "interpreter": {
   "hash": "d837fe7f89ea0bfb31f7e35050aa5bb243afc9e818f612445420203286c5c6ce"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# This notebook will serve for the initial EDA for the inquiries data for the TFW project"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Import necassary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Setup axis for plots\n",
    "sns.set_context(\"talk\", font_scale=1.5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load dataset\n",
    "df_inquiries = pd.read_csv('../data/inquiries_20210713.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Shape of the dataset\n",
    "print('The dataset contains %s inquiries and %s features' %(df_inquiries.shape[0], df_inquiries.shape[1]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Have a first look at the dataset\n",
    "df_inquiries.head(2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# First look at the info\n",
    "df_inquiries.info()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# First description of the numerical features\n",
    "round(df_inquiries.describe(),3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Looking for categorical features\n",
    "df_inquiries.nunique()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_inquiries.isna().sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Duplicate rows\n",
    "# Select duplicate rows except first occurrence based on all columns\n",
    "duplicateRowsDF = df_inquiries[df_inquiries.duplicated()]\n",
    "print(\"Duplicate Rows except first occurrence based on all columns are :\")\n",
    "print(duplicateRowsDF)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have 83 duplicated rows. We will remove them in the cleaning (see beolw).Exception"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convert date and time features to the right data type"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Convert column contract_end to datetime\n",
    "df_inquiries['date'] = pd.to_datetime(df_inquiries['date'])\n",
    "df_inquiries['time'] = pd.to_datetime(df_inquiries['time'],format= '%H:%M:%S' ).dt.time\n",
    "df_inquiries['arrival_date'] = pd.to_datetime(df_inquiries['arrival_date'])\n",
    "df_inquiries['departure_date'] = pd.to_datetime(df_inquiries['departure_date'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Looking for correlations"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# generate the heatmap\n",
    "corr = df_inquiries.corr()\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "sns.heatmap(\n",
    "    corr,\n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True\n",
    ")\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ");"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Generate table with correlations \n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plotting distribution of the features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plotting the feature title\n",
    "df_inquiries.title.hist()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plotting histograms of numerical features \n",
    "df_inquiries.hist(figsize = (20,15))\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Closer look to all features\n",
    "\n",
    "### 1. title"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Number of unique values in feature title\n",
    "print('Number of different title:', df_inquiries.title.nunique())\n",
    "print('Unique values:', df_inquiries.title.unique())\n",
    "print('Count of unique values:\\n', df_inquiries.title.value_counts())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Counts Adults, Children and Pets\n",
    "\n",
    "Looking for outliers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# boxplots\n",
    "df_inquiries.boxplot(column=['adult_count', 'children_count', 'pets_count'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In these features are outliers that we have to handle. We decided to go with the statistical procedure and cut off with quantile 0.95 like in all notebooks. This step we will do in the cleaning (see below).\n",
    "\n",
    "Looking for zero values."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Looking for zero values\n",
    "print('Number of zero values in adult count:', df_inquiries.adult_count.isin([0]).sum())\n",
    "print('Number of zero values in children count:', df_inquiries.children_count.isin([0]).sum())\n",
    "print('Number of zero values in pets count:', df_inquiries.pets_count.isin([0]).sum())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Dates: date, time, arrival date, and departure date"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Looking for the range in the features date\n",
    "print('Min date:', df_inquiries.date.min())\n",
    "print('Max date:', df_inquiries.date.max())\n",
    "print('---------------------------')\n",
    "print('Min time:', df_inquiries.time.min())\n",
    "print('Max time:', df_inquiries.time.max())\n",
    "print('---------------------------')\n",
    "print('Min arrival date:', df_inquiries.arrival_date.min())\n",
    "print('Max arrival date:', df_inquiries.arrival_date.max())\n",
    "print('---------------------------')\n",
    "print('Min departure date:', df_inquiries.departure_date.min())\n",
    "print('Max departure date:', df_inquiries.departure_date.max())\n",
    "print('---------------------------')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The arrival and departure date are far in the future. We decide to keep the arrival date (so we don't interrupt the length of stay) until 31.12.2021. The last date for inquiries is 31.12.2020, but since inquiries are made for the future, often well in advance, we decided for one year, as it seems most realistic that a booking will also be made from this. This step we will do in the cleaning (see below)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Closer view to arrival date"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "df_inquiries['arrival_date_yearmonth'] = pd.to_datetime(df_inquiries['arrival_date'],format='%Y-%m', errors='coerce').dt.to_period('m')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_arrival_date = df_inquiries.groupby('arrival_date_yearmonth').count().reset_index()[['arrival_date_yearmonth', 'listing_id']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_arrival_date['arrival_date_yearmonth'] = plot_arrival_date.arrival_date_yearmonth.astype(str)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_arrival_date['arrival_date_yearmonth'] = pd.to_datetime(plot_arrival_date['arrival_date_yearmonth'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Split dataset: 2019 and 2020\n",
    "start_date = \"2019-01\"\n",
    "end_date = \"2020-12\"\n",
    "\n",
    "after_start_date = plot_arrival_date[\"arrival_date_yearmonth\"] >= start_date\n",
    "before_end_date = plot_arrival_date[\"arrival_date_yearmonth\"] <= end_date\n",
    "between_two_dates = after_start_date & before_end_date\n",
    "filtered_dates = plot_arrival_date.loc[between_two_dates]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plotting a lineplot\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "sns.lineplot(data=filtered_dates, x=\"arrival_date_yearmonth\", y=\"listing_id\")\n",
    "ax.set(xlabel='Year - Month', ylabel='Inquiry count')\n",
    "plt.title('Overall Inquiries per Month (2019 - 2020)')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Inquiries prices\n",
    "\n",
    "Looking for outliers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# boxplots\n",
    "df_inquiries.boxplot(column=['inquiry_price'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Because of the high values, we also will go with the cut off with percentile 0.95. This step we will do in the cleaning (see below).\n",
    "\n",
    "Looking for zero values."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Zero values\n",
    "print('Number of zero values in inquiry price:', df_inquiries.inquiry_price.isin([0]).sum())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature engineering\n",
    "\n",
    "With the features arrival date and departure date we calculate a new feature length stay. The length of a stay influcences the price."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create new feature length of stay\n",
    "df_inquiries['length_stay'] = df_inquiries.departure_date - df_inquiries.arrival_date"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Looking for the range in the features length stay\n",
    "print('Min length stay:', df_inquiries.length_stay.min())\n",
    "print('Max length stay:', df_inquiries.length_stay.max())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plotting the distribution\n",
    "df_inquiries['length_stay'].dt.days.hist(bins=1000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have a wide distribution of the inquire length of stay. We will first going throw the other cleaning steps and following have a second look on this distribution again."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Clean the dataset\n",
    "\n",
    "### 1. Duplicated rows"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Remove duplicated rows\n",
    "df_inquiries.drop_duplicates(keep='first', inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Count adults, children, pets and inquiry price"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Calculate .95 quantile for the features\n",
    "print('Quantiles 0.95 for:')\n",
    "print('Adults:', df_inquiries.adult_count.quantile([.95]))\n",
    "print('Children:', df_inquiries.children_count.quantile([.95]))\n",
    "print('Pets:', df_inquiries.pets_count.quantile([.95]))\n",
    "print('inquiry_price:', df_inquiries.inquiry_price.quantile([.95]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Drop all rows with a number of adults greater than 6."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# How many rows do we drop?\n",
    "print('Number of dropping rows:', df_inquiries.query('adult_count > 6').shape[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Get names of indexes for which column adult_count has value greater than 6\n",
    "indexNames_adult_count = df_inquiries[df_inquiries['adult_count'] > 6].index\n",
    "# Delete these row indexes from dataset\n",
    "df_inquiries.drop(indexNames_adult_count , inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Drop all rows with a number of children greater than 2."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# How many rows do we drop?\n",
    "print('Number of dropping rows:', df_inquiries.query('children_count > 2').shape[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Get names of indexes for which column children_count has value greater than 2\n",
    "indexNames_children_count = df_inquiries[df_inquiries['children_count'] > 2].index\n",
    "# Delete these row indexes from dataset\n",
    "df_inquiries.drop(indexNames_children_count , inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Drop all rows with a number of pets greater than 1."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# How many rows do we drop?\n",
    "print('Number of dropping rows:', df_inquiries.query('pets_count > 1').shape[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Get names of indexes for which column pets_count has value greater than 1\n",
    "indexNames_pets_count = df_inquiries[df_inquiries['pets_count'] > 1].index\n",
    "# Delete these row indexes from dataset\n",
    "df_inquiries.drop(indexNames_pets_count , inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Drop all rows with a number of inquiry price greater than 1820.0."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# How many rows do we drop?\n",
    "print('Number of dropping rows:', df_inquiries.query('inquiry_price > 1820.0').shape[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Get names of indexes for which column inquiry_price has value greater than 1820.0\n",
    "indexNames_inquiry_price = df_inquiries[df_inquiries['inquiry_price'] > 1820.0].index\n",
    "# Delete these row indexes from dataset\n",
    "df_inquiries.drop(indexNames_inquiry_price , inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Arrival\n",
    "\n",
    "Remove dates that are greater than 31.12.2021."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Remove dates greater than 31.12.2021 \n",
    "df_inquiries = df_inquiries[pd.to_datetime(df_inquiries.arrival_date) <= pd.to_datetime('2021-12-31')]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. Length of stay"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Looking for the range in the features length stay\n",
    "print('Min length stay:', df_inquiries.length_stay.min())\n",
    "print('Max length stay:', df_inquiries.length_stay.max())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plotting the distribution\n",
    "df_inquiries['length_stay'].dt.days.hist(bins=1000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Because the distribution doen't change, we decide to clean for this column too."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Calculate .95 quantile for feature\n",
    "print('Length stay:', df_inquiries.length_stay.quantile([.95]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Convert timedelta to integer\n",
    "df_inquiries['length_stay'] = df_inquiries.length_stay.dt.days"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# How many rows do we drop?\n",
    "print('Number of dropping rows:', df_inquiries.query('length_stay > 14').shape[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Get names of indexes for which column length_stay has value greater than 14\n",
    "indexNames_length_stay = df_inquiries[df_inquiries['length_stay'] > 14].index\n",
    "# Delete these row indexes from dataset\n",
    "df_inquiries.drop(indexNames_length_stay , inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Shape of the cleaned dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Shape of the dataset\n",
    "print('The dataset contains %s inquries and %s features' %(df_inquiries.shape[0], df_inquiries.shape[1]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save clean dataset as new CSV"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Export csv\n",
    "#df_inquiries.to_csv('../data/master_inquiries_20210715.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Merge original datasets inquiries and listings"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Load the datasets\n",
    "df_listings = pd.read_csv('../data/listings_20210707.csv')\n",
    "df_inquiries = pd.read_csv('../data/inquiries_20210713.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Merging datasets\n",
    "df = pd.merge(df_inquiries, df_listings, on='listing_id', how='left')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# generate year and month from inquiry date and arrival date\n",
    "\n",
    "df['inq_year'] = pd.to_datetime(df['date']).dt.year\n",
    "df['inq_month'] = pd.to_datetime(df['date']).dt.month\n",
    "\n",
    "df['arr_year'] = pd.to_datetime(df['arrival_date']).dt.year\n",
    "df['arr_month'] = pd.to_datetime(df['arrival_date']).dt.month"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Filter for year 2019\n",
    "\n",
    "df = df[(df['inq_year'] == 2019) & (df['arr_year'] == 2019)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# TOP5 regions with the highest inquiry count\n",
    "df.region.value_counts()[:5]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# TOP5 holiday regions with the highest inquiry count\n",
    "df.holiday_region.value_counts()[:5]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# TOP5 regions with the largest number of properties\n",
    "df.groupby('region').listing_id.nunique().sort_values(ascending=False)[:5]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# TOP5 holiday regions with the largest number of properties\n",
    "df.groupby('holiday_region').listing_id.nunique().sort_values(ascending=False)[:5]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# TOP5 regions with highest inquiry count per property\n",
    "round(df.region.value_counts() / df.groupby('region').listing_id.nunique()).sort_values(ascending=False)[:5]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# TOP5 holiday regions with highest inquiry count per property\n",
    "round(df.holiday_region.value_counts() / df.groupby('holiday_region').listing_id.nunique()).sort_values(ascending=False)[:5]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Aggregate inquiry count\n",
    "inquiry_count = df.groupby(['listing_id','inq_year','inq_month']).agg(['count'])['region'].reset_index()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# rename count to inquiry_count\n",
    "inquiry_count.rename(columns={'count':'inquiry_count'},inplace=True)\n",
    "\n",
    "# merge these counts back into master set \n",
    "\n",
    "df = pd.merge(inquiry_count, df, left_on=['listing_id','inq_year','inq_month'], right_on=['listing_id','inq_year','inq_month'], how='right')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create region lists for plots: inquiry count per month\n",
    "region_list = ['Ostsee', 'Nordsee', 'Oberbayern', 'Allgäu', 'Mecklenburgische Seenplatte']\n",
    "holiday_region_list = ['Ostsee', 'Nordsee', 'Oberbayern', 'Schwarzwald', 'Oberallgäu']\n",
    "region_inquiry_property_list = ['Sächsische Schweiz', 'Spreewald', 'Bodensee', 'Thüringer Wald', 'Harz']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create sub datasets for plots: inquiry count per month\n",
    "region = df[df['region'].isin(region_list)]\n",
    "holiday_region = df[df['holiday_region'].isin(holiday_region_list)]\n",
    "region_inquiry_property = df[df['region'].isin(region_inquiry_property_list)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot: region\n",
    "ax = sns.lineplot(x=\"arr_month\", y=\"inquiry_count\", data=region, hue='region')\n",
    "ax.legend(title=\"Region\", loc='center right', bbox_to_anchor=(2.5, 0.5))\n",
    "ax.set(xlabel='Month', ylabel='Mean inquiry count')\n",
    "ax.set_xticks(range(1,13))\n",
    "ax.set_xticklabels(['J','F','M','A','M','J','J','A','S','O','N','D']);"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot: holiday_region\n",
    "ax = sns.lineplot(x=\"arr_month\", y=\"inquiry_count\", data=holiday_region, hue='holiday_region')\n",
    "ax.legend(title=\"Holiday region\", loc='center right', bbox_to_anchor=(1.9, 0.5))\n",
    "ax.set(xlabel='Month', ylabel='Mean inquiry count')\n",
    "ax.set_xticks(range(1,13))\n",
    "ax.set_xticklabels(['J','F','M','A','M','J','J','A','S','O','N','D']);"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot: Region inquiry per property\n",
    "ax = sns.lineplot(x=\"arr_month\", y=\"inquiry_count\", data=region_inquiry_property, hue='region')\n",
    "ax.legend(title=\"Region\", loc='center right', bbox_to_anchor=(2.1, 0.5))\n",
    "ax.set(xlabel='Month', ylabel='Mean inquiry count')\n",
    "ax.set_xticks(range(1,13))\n",
    "ax.set_xticklabels(['J','F','M','A','M','J','J','A','S','O','N','D']);"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}