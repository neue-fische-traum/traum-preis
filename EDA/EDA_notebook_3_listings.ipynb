{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "interpreter": {
   "hash": "2cf2762940e556d956aef20b64b564883d063a27c09be2ab447a9c75f5b30a4b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# This notebook will serve for the initial EDA for the listings data for the TFW project"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necassary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df_listings = pd.read_csv('../data/listings_20210707.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of the dataset\n",
    "print('The dataset contains %s different accommodations and %s features' %(df_listings.shape[0], df_listings.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a first look at the dataset\n",
    "df_listings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First look at the info\n",
    "df_listings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First description of the numerical features\n",
    "df_listings.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking for categorical features\n",
    "df_listings.nunique()"
   ]
  },
  {
   "source": [
    "The dataset contains many categorical features that we need to process further."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## First cleaning steps\n",
    "\n",
    "Like Traum-Ferienwohnungen told, we've got a dataset with accomodations located in Germany as we can see in the feature country_title. Because of this, we can drop this column."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the column country_title\n",
    "df_listings = df_listings.drop('country_title', axis=1)"
   ]
  },
  {
   "source": [
    "The feature `pets` includes only missing values and zeros. In my opinion, this column records the number of pets that are allowed. If pets are allowed or not (or on request) are covered in following columns: `option_holiday_with_your_pet`, `option_holiday_with_your_horse`, `option_holiday_with_your_dog`. For this reason, we decided to drop this column too."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the column pets\n",
    "print(df_listings.pets.unique())\n",
    "df_listings = df_listings.drop('pets', axis=1)"
   ]
  },
  {
   "source": [
    "## Feature converting\n",
    "\n",
    "First, convert the date feature `contract_end` to datetime."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert column contract_end to datetime\n",
    "df_listings['contract_end'] = pd.to_datetime(df_listings['contract_end'])"
   ]
  },
  {
   "source": [
    "The feature `living_area` contains values with range. Like Traum-Ferienwohnungen recommends, we take the first number as correct one and convert them to integers."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace range of `living_area` with the first number\n",
    "df_listings.replace(['70-280', '50-100', '50-70', '24-49', '16 - 26', '70-280', '18 - 26', '88-100', '46-73', '50-80', '52-65', '50-60'], ['70', '50', '50', '24', '16', '70', '18', '88', '46', '50', '52', '50'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert column `living_area`to integer\n",
    "df_listings['living_area'] = df_listings['living_area'].astype(float)"
   ]
  },
  {
   "source": [
    "To use the option features in the model, we convert the booleans / categories to integers as following:\n",
    "\n",
    "- False / no / Not allowed >> 0\n",
    "- True / yes / Allowed >> 1\n",
    "- On request >> 2\n",
    "- Unset >> 3"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacement to integers \n",
    "df_listings.replace(['False', 'no', 'not allowed', 'True', 'yes', 'allowed', 'on request', 'unset'], [0, 0, 0, 1, 1, 1, 2, 3], inplace=True)"
   ]
  },
  {
   "source": [
    "## Looking for correlations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the heatmap\n",
    "corr = df_listings.corr()\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "sns.heatmap(\n",
    "    corr,\n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True\n",
    ")\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate table with correlations \n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "source": [
    "## Plotting distribution of the features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the feature state\n",
    "df_listings.state.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the feature contract end\n",
    "df_listings.contract_end.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting histograms of numerical features \n",
    "df_listings.hist(bins=50, figsize = (30,30))\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "### Closer Look: categorical features\n",
    "\n",
    "1. The histograms of the features `option_wheelchair_accessible` and `wheelchairaccess` look very similar. A check confirmed identical columns. For this reason we drop one column."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for identical columns \n",
    "comparison_column = np.where(df_listings[\"option_wheelchair_accessible\"] == df_listings[\"wheelchairaccess\"], True, False)\n",
    "print(np.all(comparison_column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the column wheelchairaccess\n",
    "df_listings = df_listings.drop('wheelchairaccess', axis=1)"
   ]
  },
  {
   "source": [
    "2. The histograms of features `option_non_smoking_only` and `smoking` look contrary. A check confirmed contrary True / False values. For this reason we drop one column. We decided to drop the column `smoking` because the column `option_non_smoking_only` differentiate the unset and on request values."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count values for categories\n",
    "print('option_non_smoking_only:\\n', df_listings['option_non_smoking_only'].value_counts())\n",
    "print('smoking:\\n',df_listings['smoking'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sub dataset that contains only True / False values for the columns\n",
    "smoking = df_listings.query(\"option_non_smoking_only == [0 ,1] & smoking == [1, 0]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for contrary columns \n",
    "comparison_column_smoking = np.where(smoking[\"option_non_smoking_only\"] != smoking[\"smoking\"], True, False)\n",
    "print(np.all(comparison_column_smoking))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the column wheelchairaccess\n",
    "df_listings = df_listings.drop('smoking', axis=1)"
   ]
  },
  {
   "source": [
    "3. The histograms of features `close_to_the_beach` and `close_to_the_water` look very similar. All accommodations close to the beach are close to the water too. But because the differences between close to the water and close to the beach, like a dike, a habour or a lake are important for guests, we stay with both features.\n",
    "\n",
    "\n",
    "4. For the features `close_to_the_beach`, `close_to_the_water`, `option_close_to_the_skilift`, `option_railway_station` and `option_airport` the amount of unset values is high: "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate amount of unset values\n",
    "print('Percent of unset values in feature')\n",
    "print('Beach nearby:', round(df_listings.query('option_close_to_the_beach == 3').count()[1]/df_listings.shape[0]*100, 1))\n",
    "print('Water nearby:', round(df_listings.query('option_close_to_the_water == 3').count()[1]/df_listings.shape[0]*100, 1))\n",
    "print('Ski lift nearby:', round(df_listings.query('option_close_to_the_ski_lift == 3').count()[1]/df_listings.shape[0]*100, 1))\n",
    "print('Railway station:', round(df_listings.query('option_railway_station == 3').count()[1]/df_listings.shape[0]*100, 1))\n",
    "print('Airport:', round(df_listings.query('option_airport == 3').count()[1]/df_listings.shape[0]*100, 1))"
   ]
  },
  {
   "source": [
    "Because of high number of unset values in the features `option_railway_station` (95.2%) and `option_airport` (98.2%) we will drop these columns because it gives us no important information. At the moment we will keep the features ` option_close_to_the_beach` (67%), `option_close_to_the_water` (63.8%) and `option_close_to_the_ski_lift` (80.7%) because they could be important for the clsutering model and these features are an important information for the guest to decide for their right accommodation."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the column option_railway_station and option_airport\n",
    "df_listings = df_listings.drop(['option_railway_station', 'option_airport'], axis=1)"
   ]
  },
  {
   "source": [
    "5. We decided to keep only the information internet and not the single features `wifi` and `internet`. Because it's important to know if a property have internet and not which kind of internet. For this reason we change a no / 0 for feature `internet` to yes / 1, if in the feature `wifi` is a yes / 1."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace value from column internet with column wifi\n",
    "df_listings['internet'] = np.where(df_listings['internet'] == 0, df_listings['wifi'], df_listings['internet'])"
   ]
  },
  {
   "source": [
    "### Closer Look: numerical features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Bathrooms"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description of the feature bathrooms\n",
    "df_listings.bathrooms.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of accommodation per bathroom number\n",
    "df_listings.groupby('bathrooms')['listing_id'].count()"
   ]
  },
  {
   "source": [
    "We have a few accommodations with a high number of bathrooms and we have to decide how we want to handle this."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because of a higher correlation between the numerical features, we're looking for the median value for all features per bathroom number to see if there is a connection \n",
    "numerical_features = df_listings[['bathrooms', 'bedrooms', 'max_guests', 'living_area']]\n",
    "numerical_features.groupby('bathrooms').median()"
   ]
  },
  {
   "source": [
    "With a higher number of bathrooms the number of bedrooms, maximum guests and living area also increase."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Bedrooms"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description of the feature bedrooms\n",
    "df_listings.bedrooms.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of accommodation per bedroom number\n",
    "df_listings.groupby('bedrooms')['listing_id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because of a higher correlation between the numerical features, we're looking for the median value for all features per bedroom number to see if there is a connection \n",
    "numerical_features.groupby('bedrooms').median()"
   ]
  },
  {
   "source": [
    "With a higher number of bedrooms the number of bathrooms, maximum guests and living area also increase."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Maximum guests"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description of the feature maximum guests\n",
    "df_listings.max_guests.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of accommodation per maximum guest number\n",
    "df_listings.groupby('max_guests')['listing_id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because of a higher correlation between the numerical features, we're looking for the median value for all features per maximum guests number to see if there is a connection \n",
    "numerical_features.groupby('max_guests').median()"
   ]
  },
  {
   "source": [
    "With a higher number of maximum guests the number of bathrooms, bedrooms and living area increase not constantly. There is no pattern."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Living area"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description of the feature maximum guests\n",
    "df_listings.living_area.describe()"
   ]
  },
  {
   "source": [
    "## EDA: Regions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "In this part, we are looking at the features `region`, `subregion`, `holiday_region`, and `zipcode`. The number of different regions, the name of the regions and the distribution will be the output."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 1. Region"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number and names of region\n",
    "print(' Number of different regions:', df_listings.region.nunique())\n",
    "print(df_listings.region.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "df_listings.region.hist(bins= 29)\n",
    "plt.xticks(rotation='vertical');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort regions by highest value\n",
    "df_listings.groupby('region')['listing_id'].count().sort_values(ascending=False)"
   ]
  },
  {
   "source": [
    "### 2. Subregion"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number and names of subregions\n",
    "print('Number of different subregions:', df_listings.subregion.nunique())\n",
    "print(df_listings.subregion.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution\n",
    "fig, ax = plt.subplots(figsize=(30,5))\n",
    "df_listings.subregion.hist(bins=196)\n",
    "plt.xticks(rotation='vertical');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort subregion by highest value\n",
    "df_listings.groupby('subregion')['listing_id'].count().sort_values(ascending=False)"
   ]
  },
  {
   "source": [
    "### 3. Holiday region"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number and names of holiday regions\n",
    "print('Number of different holdiday regions:', df_listings.holiday_region.nunique())\n",
    "print(df_listings.holiday_region.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "df_listings.holiday_region.hist(bins=29)\n",
    "plt.xticks(rotation='vertical');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort holiday region by highest value\n",
    "df_listings.groupby('holiday_region')['listing_id'].count().sort_values(ascending=False)"
   ]
  },
  {
   "source": [
    "### 4. Zipcode"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number and names of zipcodes\n",
    "print('Number of different zipcodes:', df_listings.zip.nunique())\n",
    "print(df_listings.zip.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution\n",
    "fig, ax = plt.subplots(figsize=(30,5))\n",
    "df_listings.zip.hist(bins=302)\n",
    "plt.xticks(rotation='vertical');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort zipcode by highest value\n",
    "df_listings.groupby('zip')['listing_id'].count().sort_values(ascending=False)"
   ]
  },
  {
   "source": [
    "## EDA: property type"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number and names of property types\n",
    "print('Number of different property type:', df_listings.property_type.nunique())\n",
    "print(df_listings.property_type.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "df_listings.property_type.hist(bins=25)\n",
    "plt.xticks(rotation='vertical');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort property type by highest value\n",
    "df_listings.groupby('property_type')['listing_id'].count().sort_values(ascending=False)"
   ]
  },
  {
   "source": [
    "# Data Cleaning\n",
    "## 1. Outliers in numerical values\n",
    "\n",
    "First, we look at the boxplots to get an overview about the outliers in the numerical features. After this we look for different quantiles to decide the cut off threshold."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplots bathrooms, bedrooms\n",
    "df_listings.boxplot(column=['bathrooms', 'bedrooms'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot maximum guests\n",
    "df_listings.boxplot(column='max_guests')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot living area\n",
    "df_listings.boxplot(column='living_area')"
   ]
  },
  {
   "source": [
    "We decided to go with the statistical procedure and cut off with quantile 0.95. For this, we look for the cut off threshold for all numerical features. With this procedure we drop extreme houses and set the focus to the 'standard' houses. The probability that a new customer has a 'standard' house is much higher than having a special house. So we want to model a good price calculator for 'standard' houses because for special houses the calculator would be inaccurate no matter if we keep them or not. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate .95 quantile for numerical features\n",
    "print('Quantiles 0.95 for:')\n",
    "print('Bathrooms:', df_listings.bathrooms.quantile([.95]))\n",
    "print('Bedrooms:', df_listings.bedrooms.quantile([.95]))\n",
    "print('Maximum guests:', df_listings.max_guests.quantile([.95]))\n",
    "print('Living_area:', df_listings.living_area.quantile([.95]))"
   ]
  },
  {
   "source": [
    "### Cleaning procedure Outliers: we start with the bedrooms, continue with bathrooms, maximum guests and living area.\n",
    "\n",
    "**A. Outliers bedrooms**\n",
    "\n",
    "Drop all rows with a number of bedrooms greater than 3."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many rows do we drop?\n",
    "print('Number of dropping rows:', df_listings.query('bedrooms > 3').shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get names of indexes for which column bedrooms has value greater than 3\n",
    "indexNames_bedrooms = df_listings[df_listings['bedrooms'] > 3].index\n",
    "# Delete these row indexes from dataset\n",
    "df_listings.drop(indexNames_bedrooms , inplace=True)"
   ]
  },
  {
   "source": [
    "**B. Outliers bathrooms**\n",
    "\n",
    "Drop all rows with a number of bathrooms greater than 2."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many rows do we drop?\n",
    "print('Number of dropping rows:',df_listings.query('bathrooms > 2').shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get names of indexes for which column bathrooms has value greater than 2\n",
    "indexNames_bathrooms = df_listings[df_listings['bathrooms'] > 2].index\n",
    "# Delete these row indexes from dataset\n",
    "df_listings.drop(indexNames_bathrooms , inplace=True)"
   ]
  },
  {
   "source": [
    "** C. Outliers maximum guests**\n",
    "\n",
    "We drop all rows with a greater number of maximum guests than 8."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many rows do we drop?\n",
    "print('Number of dropping rows:', df_listings.query('max_guests > 8').shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get names of indexes for which column maximum guests has value greater than 8\n",
    "indexNames_guests = df_listings[df_listings['max_guests'] > 8].index\n",
    "# Delete these row indexes from dataset\n",
    "df_listings.drop(indexNames_guests , inplace=True)"
   ]
  },
  {
   "source": [
    "** D. Outliers living area**\n",
    "\n",
    "We drop all rows with a greater number of living area than 140."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many rows do we drop?\n",
    "print('Number of dropping rows:', df_listings.query('living_area > 140').shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get names of indexes for which column living area has value greater than 140\n",
    "indexNames_living_area = df_listings[df_listings['living_area'] > 140].index\n",
    "# Delete these row indexes from dataset\n",
    "df_listings.drop(indexNames_living_area , inplace=True)"
   ]
  },
  {
   "source": [
    "### Description of numerical features after cleaning the dataset for outliers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking for the description of the numerical features after dropping the outliers\n",
    "df_listings[numerical_features.columns].describe()"
   ]
  },
  {
   "source": [
    "## 3. Property type\n",
    "\n",
    "If we want to model a good price calculator for 'standard' houses we have to look at the property type again. As we saw in the EDA, the distribution is widely."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "df_listings.property_type.hist(bins=25)\n",
    "plt.xticks(rotation='vertical');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort property type by highest value\n",
    "df_listings.groupby('property_type')['listing_id'].count().sort_values(ascending=False)"
   ]
  },
  {
   "source": [
    "We will keep the first three property types (holiday apartment, holiday houses, apartment, and bungalow >> Traum-Ferienwohnungen mentioned that holiday apartment and apartment practically are the same) because they have the highest amount in the dataset and the other property types seems to be special houses."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop special property types\n",
    "df_listings = df_listings[df_listings['property_type'].isin(['holiday_apartment', 'holiday_houses', 'apartment', 'bungalow'])]\n",
    "print('The clean dataset contains:', df_listings.shape[0], 'unique properties.')"
   ]
  },
  {
   "source": [
    "## 2. Missing values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking for missing values\n",
    "df_listings.isna().sum()"
   ]
  },
  {
   "source": [
    "We have one missing value in `subregion`, 430 missing values in `bathrooms`, `bedrooms`, and `max_guests` and 431 missing values in `living_area`.\n",
    "\n",
    "First, we drop the 430 rows with missing values for `bathrooms`, `bedrooms` and `max_guests`. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the missing values\n",
    "df_listings.dropna(subset=['bathrooms'], inplace=True)"
   ]
  },
  {
   "source": [
    "Second, we are looking for the two rows with missing values to decide how to replace them."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show rows with missing values to decide how to replace them\n",
    "df_listings[df_listings.isnull().any(axis=1)]"
   ]
  },
  {
   "source": [
    "We decided to replace the subregion with the mode value for this zipcode (237--)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking for the mode value for this zipcode and replace it\n",
    "df_listings[df_listings['zip'] == '237--']['subregion'].value_counts()"
   ]
  },
  {
   "source": [
    "Lübecker Bucht is the mode. So we replace with this value."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing value with mode value for this zipcode\n",
    "df_listings[\"subregion\"] = df_listings[\"subregion\"].fillna(\"Lübecker Bucht\")"
   ]
  },
  {
   "source": [
    "We calculate the mean living area for a property with 1 bathroom, 2 bedrooms, and a number of maximum guests of 4."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing value with mean value for the property room numbers\n",
    "df_listings[\"living_area\"] = df_listings[\"living_area\"].fillna(round(df_listings.query('bathrooms == 1 & bedrooms == 2 & max_guests == 4').mean()['living_area'], 1))"
   ]
  },
  {
   "source": [
    "## 3. Zero values\n",
    "In the dataset are also zero values for bathrooms and bedrooms. Traum-Ferienwohnungen mentioned that this is possible for different reasons, so we keep this values."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero values\n",
    "print('Zero values')\n",
    "print('Bathrooms:', df_listings.query('bathrooms == 0').shape[0])\n",
    "print('Bedrooms:', df_listings.query('bedrooms == 0').shape[0])"
   ]
  },
  {
   "source": [
    "## New EDA after cleaning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Distribution of the numerical features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting histograms for the features \n",
    "df_listings.hist(bins=50, figsize = (30,30))\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "#### Closer look to some features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count values for categories\n",
    "print('Non Smoking:\\n', df_listings['option_non_smoking_only'].value_counts())\n",
    "print('--------------------')\n",
    "print('Airconditioner:\\n', df_listings['airconditioner'].value_counts())\n",
    "print('--------------------')\n",
    "print('Family travel:\\n', df_listings['option_family_travel'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Percent of false values in feature')\n",
    "print('Non smoking:', round(df_listings.query('option_non_smoking_only == 1').count()[1]/df_listings.shape[0]*100, 1))\n",
    "print('Airconditioner:', round(df_listings.query('airconditioner == 0').count()[1]/df_listings.shape[0]*100, 1))\n",
    "print('Family travel:', round(df_listings.query('option_family_travel == 1').count()[1]/df_listings.shape[0]*100, 1))"
   ]
  },
  {
   "source": [
    "Because of the high value for no airconditioner (98.9%) we drop this column because it has no information for us. We still keep the feature non smoking (96.6% true) because it's an important information for the guests."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop airconditioner\n",
    "df_listings = df_listings.drop('airconditioner', axis=1)"
   ]
  },
  {
   "source": [
    "### Overview about the Regions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number and names of region\n",
    "print(' Number of different regions:', df_listings.region.nunique())\n",
    "print(' Number of different subregions:', df_listings.subregion.nunique())\n",
    "print(' Number of different holiday regions:', df_listings.holiday_region.nunique())\n",
    "print(' Number of different zipcodes:', df_listings.zip.nunique())"
   ]
  },
  {
   "source": [
    "We lost three subregions and eleve zipcodes with our data cleaning."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Shape of the cleaned dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of the dataset\n",
    "print('The dataset contains %s different properties and %s features.' %(df_listings.shape[0], df_listings.shape[1]))\n",
    "print('The %s properties are owned by %s customers.' %(df_listings.shape[0], df_listings.customer_id.nunique()))\n",
    "print('So in average each customer owns %s properties.' %(df_listings.shape[0]/df_listings.customer_id.nunique()))"
   ]
  },
  {
   "source": [
    "# Merge mean latitude and longitude for zip code and merge with listings"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df_zipcode = pd.read_csv('../data/plz_geocoord.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the unnamed column\n",
    "df_zipcode.rename(columns={\"Unnamed: 0\": \"zip\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove last two digits in the feature postal_code to merge with dataset listings\n",
    "df_zipcode['zip'] = df_zipcode['zip'].floordiv(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add leading Zeros to postal code to get a postal code of 5 digits\n",
    "df_zipcode['zip'] = df_zipcode['zip'].apply(lambda x: '{0:0>3}'.format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace comma with dot\n",
    "df_zipcode = df_zipcode.apply(lambda x: x.str.replace(',','.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert latitude and longitude to numerical values\n",
    "df_zipcode['lat'] = pd.to_numeric(df_zipcode['lat'])\n",
    "df_zipcode['lng'] = pd.to_numeric(df_zipcode['lng'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby zipcode to calculate the mean for latitude and longitude\n",
    "df_zipcode = df_zipcode.groupby('zip').mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export csv master zipcode\n",
    "#df_zipcode.to_csv('../data/master_zipcode_20210715.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace comma with dot in dataset listings for merging\n",
    "df_listings['zip'] = df_listings['zip'].apply(lambda x: x.replace('--',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge both datasets listings and zipcode\n",
    "df_master = pd.merge(df_listings, df_zipcode, how='left', on='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for checking if everything looks fine\n",
    "# Extract the data we're interested in\n",
    "lat, lon = df_master['lat'], df_master['lng']\n",
    "properties, zipcode = df_master['listing_id'], df_master['zip']\n",
    "\n",
    "# Scatter the points, using size and color but no label\n",
    "plt.scatter(lon, lat, label=None,\n",
    "            cmap='viridis',\n",
    "            linewidth=0, alpha=0.5)\n",
    "#plt.axis(aspect='equal')\n",
    "plt.xlabel('longitude')\n",
    "plt.ylabel('latitude')\n",
    "\n",
    "plt.title('Traum-Ferienwohnungen: Properties and zipcode');"
   ]
  },
  {
   "source": [
    "# Save cleaned dataset in a new CSV"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export csv\n",
    "#df_listings.to_csv('../data/master_listings_20210715.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}