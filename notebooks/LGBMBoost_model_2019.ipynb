{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# this notebook prepares the data and implements the code to run the LGBM Boost model for TFW"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import sys\n",
    "# adding to the path variables the one folder higher (locally, not changing system variables)\n",
    "sys.path.append(\"..\")\n",
    "import pandas as pd\n",
    "# from pandas_profiling import ProfileReport\n",
    "import numpy as np\n",
    "import warnings\n",
    "import mlflow\n",
    "from modeling.config import EXPERIMENT_NAME\n",
    "TRACKING_URI = open(\"../.mlflow_uri\").read().strip()\n",
    "\n",
    "ROOT = os.environ.get('PWD')\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data cleaning and feature engineering"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# set global default to be able to see all columns\n",
    "\n",
    "pd.set_option('display.max_rows', None)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# read from csv\n",
    "\n",
    "master = pd.read_csv('../data/excellent_master.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# check the state of the data\n",
    "\n",
    "len(master)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "list(master.columns.values)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# drop necessary columns\n",
    "drop_list = ['Unnamed: 0','Unnamed: 0.1','Unnamed: 0_x','Unnamed: 0_y','arrival_date']\n",
    "\n",
    "for i in drop_list:\n",
    "    master.drop([i],axis=1,inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "master.nunique()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# select the filter that is appropriate for the data range. \n",
    "# NOTE: the range is not automatically reflected in the name of the dataframe--\n",
    "# but it should be put into the parameters for ML Flow\n",
    "\n",
    "# by default, the master set has both years, 2019 and 2020, so it needs no filter\n",
    "\n",
    "# master_filter = master\n",
    "\n",
    "# to filter only 2019 data\n",
    "master_filter = master.query('year == 2019').reset_index()\n",
    "\n",
    "# to filter only 2020 data\n",
    "# master_filter = master.query('year == 2020')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "master_filter.isna().sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## the data set has no missing values"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# generate the feature mean_price_per_day \n",
    "\n",
    "master_filter_price_agg = master_filter.groupby(['listing_id','month']).agg(['mean'])['filled_in_price_per_day'].reset_index()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "master_filter_1 = pd.merge(master_filter_price_agg, master_filter, left_on=['listing_id','month'], right_on=['listing_id','month'], how='right')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "master_filter_1.rename(columns={'mean':'mean_price_per_day'},inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# check the values\n",
    "\n",
    "master_filter_1.nunique()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(master_filter_1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "list(master_filter_1.columns.values)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# drop more things that need not be in the data set\n",
    "\n",
    "drop_list = ['year',\n",
    " 'option_holiday_with_your_pet','option_holiday_with_your_horse']\n",
    "\n",
    "for i in drop_list:\n",
    "    master_filter_1.drop([i],axis=1,inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "master_filter_1.drop(['index'],axis=1,inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# save to csv if desired: this is the normed, filtered set with agg price data for the years in question\n",
    "\n",
    "master_filter_1.to_csv('../data/master_filter_price_agg.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "master_filter_1 = pd.read_csv('../data/master_filter_price_agg.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "master_filter_1['property_type'].unique()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# convert property types into binary: holiday apartment = 0, and holiday_houses = 1\n",
    "master_filter_1['prop_bin'] = 1\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "master_filter_1.loc[master_filter_1['property_type'] == 'holiday_apartment', 'prop_bin'] = 0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "master_filter_1.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# drop unneeded columns\n",
    "\n",
    "master_filter_1.drop(['filled_in_price_per_day','property_type','option_technicians'],axis=1,inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# trying not to be a dummy by getting dummies\n",
    "master_dummies = pd.get_dummies(master_filter_1, columns=['holiday_region','title','option_allergic',\n",
    " 'option_non_smoking_only',\n",
    " 'option_holiday_with_your_dog',\n",
    " 'option_close_to_the_beach',\n",
    " 'option_wheelchair_accessible',\n",
    " 'option_family_travel',\n",
    " 'option_close_to_the_water',\n",
    " 'option_holiday_with_your_baby',\n",
    " 'option_long_term_holiday',\n",
    " 'option_fully_accessible',\n",
    " 'option_close_to_the_ski_lift'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "list(master_dummies.columns_values)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# LGBM needs to have no unusual characters in the column names\n",
    "\n",
    "master_dummies.columns = master_dummies.columns.str.replace(\"[_]\", \"\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "master_dummies.head(2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# move now to do the train test split and then the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# create X and Y sets for train test split, this is especially important for LGBM, because it can overfit and we need to verify good fit by comparing to holdout data\n",
    "\n",
    "X = master_dummies.drop(['listingid','inquirycount'],axis=1)\n",
    "Y = master_dummies['inquirycount']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# train test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.30, random_state=42)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Trainining the model and tracking with MLFlow"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "mlflow.start_run()\n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#training the model\n",
    "# !pip install --upgrade pip\n",
    "# !pip install lightgbm\n",
    "\n",
    "from lightgbm import LGBMRegressor\n"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# set LGBM parameters\n",
    "\n",
    "clf = LGBMRegressor(\n",
    "    n_estimators=400,\n",
    "    learning_rate=0.01,\n",
    "    colsample_bytree=.8,\n",
    "    max_depth=10,\n",
    "    reg_alpha=.1,\n",
    "    reg_lambda=.1,\n",
    "    min_split_gain=.01,\n",
    "    min_child_weight=2,\n",
    "    silent=-1,\n",
    "    verbose=-1,\n",
    ")\n",
    "\n",
    "clf.fit(\n",
    "    X_train, y_train, \n",
    "    eval_set= [(X_train, y_train), (X_test, y_test)], \n",
    "    eval_metric='rmse', verbose=100, early_stopping_rounds=100  #100\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# install and use SHAP to check feature importance\n",
    "\n",
    "# !pip install shap\n",
    "\n",
    "import shap\n",
    "import matplotlib.pyplot as pl \n",
    "shap_values = shap.TreeExplainer(clf.booster_).shap_values(X_train.iloc[:10000,:])\n",
    "shap_values.shape\n",
    "\n",
    "\n",
    "# get importances from the shap values\n",
    "global_importances = np.abs(shap_values).mean(0)[:-1]\n",
    "\n",
    "\n",
    "# make a bar chart that shows the global importance of the top 10 features\n",
    "inds = np.argsort(-global_importances)\n",
    "f = pl.figure(figsize=(5,10))\n",
    "y_pos = np.arange(10)\n",
    "inds2 = np.flip(inds[:10], 0)\n",
    "pl.barh(y_pos, global_importances[inds2], align='center', color=\"#1E88E5\")\n",
    "pl.yticks(y_pos, fontsize=13)\n",
    "pl.gca().set_yticklabels(X_train.columns[inds2])\n",
    "pl.xlabel('mean abs. SHAP value (impact on model output)', fontsize=13)\n",
    "pl.gca().xaxis.set_ticks_position('bottom')\n",
    "pl.gca().yaxis.set_ticks_position('none')\n",
    "pl.gca().spines['right'].set_visible(False)\n",
    "pl.gca().spines['top'].set_visible(False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# plot residuals\n",
    "\n",
    "sns.residplot(x=y_test, y=y_test_pred)\n",
    "\n",
    "plt.scatter(y=y_test, x=y_test_pred)\n",
    "plt.plot(y_test_pred, y_test_pred, color='orange')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title(f'Actual VS Predicted Inquiries')\n",
    "plt.show()\n",
    "\n",
    "plt.axhline(0, c=(.5, .5, .5), ls='--')\n",
    "plt.axvline(0, c=(.5, .5, .5), ls='--')\n",
    "plt.scatter(x=y_test_pred, y=y_residual)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# set MLFlow parameters\n",
    "\n",
    "params = {\n",
    "      \"model\":\"LightGBMBoost\",\n",
    "      \"year\":'2019',\n",
    "      \"train_test_split\": 30,\n",
    "      \"normalized data\": 'yes',\n",
    "      \"metric\": 'rmse'\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mlflow.log_params(params)\n",
    "mlflow.set_tag(\"running_from_jupyter\", \"baseline model 2019\")\n",
    "mlflow.log_metric(\"train -\" + \"RMSE\", rmse_train)\n",
    "mlflow.log_metric(\"test -\" + \"RMSE\", rmse_test)\n",
    "# mlflow.log_artifact(\"../models\")\n",
    "# mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Checking the experiments\n",
    "\n",
    "while the next cell is running you will not be able to run other cells in the notebook"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!mlflow ui"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('.venv')"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  },
  "interpreter": {
   "hash": "50124f71d8f3ce399cc8f90e232172b7703f7c279ffa8eaec14b162019ba404a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}