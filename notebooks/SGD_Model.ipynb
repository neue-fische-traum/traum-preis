{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# This notebook serves to create a model using SGD model for our TFW data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import sys\n",
    "# adding to the path variables the one folder higher (locally, not changing system variables)\n",
    "sys.path.append(\"..\")\n",
    "import pandas as pd\n",
    "# from pandas_profiling import ProfileReport\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "import warnings\n",
    "import mlflow\n",
    "from modeling.config import EXPERIMENT_NAME\n",
    "TRACKING_URI = open(\"../.mlflow_uri\").read().strip()\n",
    "\n",
    "ROOT = os.environ.get('PWD')\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data cleaning and feature engineering has taken place to run the baseline model, this data set will be used as it is for running the top secret model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# set global default to be able to see all columns\n",
    "\n",
    "pd.set_option('display.max_rows', None)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# read data from csv: this is the time normed, filtered set with agg price data for the years in question\n",
    "\n",
    "master_dummies = pd.read_csv('../data/master_with_dummies_1.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# create X and Y sets for train test split\n",
    "\n",
    "X = master_dummies.drop(['listing_id','inquiry_count'],axis=1)\n",
    "Y = master_dummies['inquiry_count']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# train test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.30, random_state=42)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# we love to normalize our data!!\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "the_list = ['mean_price_per_day','adult_count','children_count','pets_count','length_stay','bathrooms','bedrooms','max_guests','living_area']"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Scaling with MinMaxScaler\n",
    "scaler_norm = MinMaxScaler()\n",
    "X_train_scaled_norm = scaler_norm.fit_transform(X_train[the_list])\n",
    "X_test_scaled_norm = scaler_norm.transform(X_test[the_list])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Concatenating normalized columns \n",
    "X_train_preprocessed_norm = np.concatenate([X_train_scaled_norm, X_train.drop(the_list, axis=1)], axis=1)\n",
    "X_test_preprocessed_norm = np.concatenate([X_test_scaled_norm, X_test.drop(the_list, axis=1)], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train_preprocessed_norm.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_test_preprocessed_norm.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Trainining the model and tracking with MLFlow"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "mlflow.start_run()\n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# set the model to SDGRegessor\n",
    "# \n",
    "\n",
    "reg = SGDRegressor()\n",
    "reg.fit(X_train_preprocessed_norm, y_train)\n"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "score = reg.score(X_train_preprocessed_norm, y_train)\n",
    "y_pred_train = reg.predict(X_train_preprocessed_norm)\n",
    "y_pred_test = reg.predict(X_test_preprocessed_norm)\n",
    " \n",
    "rmse_train = mean_squared_error(y_train, y_pred_train, squared=False)\n",
    "rmse_test = mean_squared_error(y_test, y_pred_test, squared=False)\n",
    "\n",
    "print(\"R-squared:\", score)\n",
    "print(\"RMSE train:\", rmse_train)\n",
    "print(\"RMSE test:\", rmse_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "params = {\n",
    "      \"model\":\"SGD\",\n",
    "      \"year\":'2019',\n",
    "      \"train_test_split\": 30,\n",
    "      \"normalized data\": 'yes',\n",
    "      \"metric\": 'rmse and R2'\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mlflow.log_params(params)\n",
    "mlflow.set_tag(\"running_from_jupyter\", \"SVR model 2019\")\n",
    "mlflow.log_metric(\"train -\" + \"RMSE\", rmse_train)\n",
    "mlflow.log_metric(\"test -\" + \"RMSE\", rmse_test)\n",
    "# mlflow.log_artifact(\"../models\")\n",
    "# mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Checking the experiments\n",
    "\n",
    "while the next cell is running you will not be able to run other cells in the notebook"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!mlflow ui"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('.venv')"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  },
  "interpreter": {
   "hash": "50124f71d8f3ce399cc8f90e232172b7703f7c279ffa8eaec14b162019ba404a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}