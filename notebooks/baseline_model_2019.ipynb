{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# this notebook implements the feature engineering and basic code features to develop the baseline model and implement MLFlow"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import sys\n",
    "# adding to the path variables the one folder higher (locally, not changing system variables)\n",
    "sys.path.append(\"..\")\n",
    "import pandas as pd\n",
    "# from pandas_profiling import ProfileReport\n",
    "import numpy as np\n",
    "import warnings\n",
    "import mlflow\n",
    "from modeling.config import EXPERIMENT_NAME\n",
    "TRACKING_URI = open(\"../.mlflow_uri\").read().strip()\n",
    "\n",
    "ROOT = os.environ.get('PWD')\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data cleaning and feature engineering"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# set global default to be able to see all columns\n",
    "\n",
    "pd.set_option('display.max_rows', None)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# read from csv\n",
    "\n",
    "master = pd.read_csv('../data/super_master.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "list(master.columns.values)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# drop necessary columns\n",
    "drop_list = ['Unnamed: 0','Unnamed: 0.1','Unnamed: 0_x','Unnamed: 0_y','arrival_date']\n",
    "\n",
    "for i in drop_list:\n",
    "    master.drop([i],axis=1,inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# check to confirm that the data looks as it should\n",
    "\n",
    "master.nunique()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# select the filter that is appropriate for the data range. \n",
    "# NOTE: the range is not automatically reflected in the name of the dataframe--\n",
    "# but it should be put into the parameters for ML Flow\n",
    "\n",
    "# by default, the master set has both years, 2019 and 2020, so it needs no filter\n",
    "\n",
    "# master_filter = master\n",
    "\n",
    "# to filter only 2019 data\n",
    "master_filter = master.query('year == 2019')\n",
    "\n",
    "# to filter only 2020 data\n",
    "# master_filter = master.query('year == 2020')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "master_filter.tail()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "master_filter.isna().sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## the data set has no missing values"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# we now need to normalize on time to remove seasonality \n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import math \n",
    "\n",
    "# We normalize x values to match with the 0-2Ï€ cycle\n",
    "master_filter[\"month_norm\"] = 2 * math.pi * master_filter[\"month\"] / master_filter[\"month\"].max()\n",
    "\n",
    "master_filter[\"cos_month\"] = np.cos(master_filter[\"month_norm\"])\n",
    "master_filter[\"sin_month\"] = np.sin(master_filter[\"month_norm\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "master_filter[\"month_norm\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# save filtered, normed to csv\n",
    "\n",
    "master_filter.to_csv('../data/master_filter.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# read filtered, normed time data\n",
    "#  \n",
    "master_filter = pd.read_csv('../data/master_filter.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# generate the feature mean_price_per_day \n",
    "\n",
    "master_filter_price_agg = master_filter.groupby(['listing_id','month']).agg(['mean'])['filled_in_price_per_day'].reset_index()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# merge aggregate data back into master set\n",
    "\n",
    "master_filter_1 = pd.merge(master_filter_price_agg, master_filter, left_on=['listing_id','month'], right_on=['listing_id','month'], how='right')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# rename column so it is more easily recognizer\n",
    "\n",
    "master_filter_1.rename(columns={'mean':'mean_price_per_day'},inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# confirm rename\n",
    "\n",
    "list(master_filter_1.columns.values)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# drop more things that need not be in the data set for the baseline model\n",
    "\n",
    "drop_list = ['filled_in_price_per_day','option_wheelchair_accessible','option_family_travel',\n",
    "'option_close_to_the_water','option_holiday_with_your_baby',\n",
    " 'option_long_term_holiday',\n",
    " 'option_fully_accessible',\n",
    " 'option_technicians',\n",
    " 'option_close_to_the_ski_lift','max_price_per_day',\n",
    " 'min_price_per_day','month_norm','year','month',\n",
    " 'option_holiday_with_your_dog','option_holiday_with_your_horse']\n",
    "\n",
    "for i in drop_list:\n",
    "    master_filter_1.drop([i],axis=1,inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# save to csv if desired: this is the normed, filtered set with agg price data for the years in question\n",
    "\n",
    "master_filter_1.to_csv('../data/master_filter_price_agg.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# read in from csv in case memory proved to be an issue\n",
    "\n",
    "master_filter_1 = pd.read_csv('../data/master_filter_price_agg.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# convert property types into binary: holiday apartment = 0, and holiday_houses = 1\n",
    "\n",
    "master_filter_1['property_type'].unique()\n",
    "master_filter_1['prop_bin'] = 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "master_filter_1.loc[master_filter_1['property_type'] == 'holiday_apartment', 'prop_bin'] = 0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "master_filter_1.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# more drops\n",
    "drop_list =['property_type','Unnamed: 0']\n",
    "\n",
    "for i in drop_list:\n",
    "    master_filter_1.drop([i],axis=1,inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# confirm variable title requires getting dummies\n",
    "\n",
    "master_filter_1['title'].unique()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# trying not to be a dummy by getting dummies\n",
    "\n",
    "master_dummies = pd.get_dummies(master_filter_1, columns=['holiday_region','title','option_allergic','option_non_smoking_only','option_holiday_with_your_pet','option_close_to_the_beach'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# save to csv if desired: this is the normed, filtered set with agg price data for the years in question\n",
    "\n",
    "master_dummies.to_csv('../data/master_with_dummies.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# read from csv\n",
    "\n",
    "master_dummies_1 = pd.read_csv('../data/master_with_dummies_1.csv')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "master_dummies = master_dummies_1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# free up memory\n",
    "\n",
    "import gc\n",
    "del master_filter_1\n",
    "gc.collect()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# move now to do the train test split and then the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# create X and Y sets for train test split\n",
    "\n",
    "X = master_dummies.drop(['listing_id','inquiry_count'],axis=1)\n",
    "Y = master_dummies['inquiry_count']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# train test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.30, random_state=42)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# we love to normalize our data!!\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "the_list = ['mean_price_per_day','adult_count','children_count','pets_count','length_stay','bathrooms','bedrooms','max_guests','living_area']\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Scaling with MinMaxScaler, do at this stage to prevent data leakage\n",
    "scaler_norm = MinMaxScaler()\n",
    "X_train_scaled_norm = scaler_norm.fit_transform(X_train[the_list])\n",
    "X_test_scaled_norm = scaler_norm.transform(X_test[the_list])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Concatenating normalized columns \n",
    "X_train_preprocessed_norm = np.concatenate([X_train_scaled_norm, X_train.drop(the_list, axis=1)], axis=1)\n",
    "X_test_preprocessed_norm = np.concatenate([X_test_scaled_norm, X_test.drop(the_list, axis=1)], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# confirm things look as they should\n",
    "\n",
    "X_train_preprocessed_norm.shape\n",
    "X_test_preprocessed_norm.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Trainining the model and tracking with MLFlow"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "mlflow.start_run()\n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#training the model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression().fit(X_train_preprocessed_norm, y_train)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "y_train_pred = reg.predict(X_train_preprocessed_norm)\n",
    "rmse_train = mean_squared_error(y_train, y_train_pred,squared=False)\n",
    "print(rmse_train)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_test_pred = reg.predict(X_test_preprocessed_norm)\n",
    "rmse_test = mean_squared_error(y_test, y_test_pred,squared=False)\n",
    "print(rmse_test)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# MLFlow parameters\n",
    "\n",
    "params = {\n",
    "      \"model\":\"linear regression\",\n",
    "      \"year\":'2019',\n",
    "      \"train_test_split\": 30,\n",
    "      \"normalized data\": 'yes',\n",
    "      \"metric\": 'rmse'\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mlflow.log_params(params)\n",
    "mlflow.set_tag(\"running_from_jupyter\", \"baseline model 2019\")\n",
    "mlflow.log_metric(\"train -\" + \"RMSE\", rmse_train)\n",
    "mlflow.log_metric(\"test -\" + \"RMSE\", rmse_test)\n",
    "# mlflow.log_artifact(\"../models\")\n",
    "# mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Checking the experiments\n",
    "\n",
    "while the next cell is running you will not be able to run other cells in the notebook"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# !mlflow ui"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('.venv': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  },
  "interpreter": {
   "hash": "50124f71d8f3ce399cc8f90e232172b7703f7c279ffa8eaec14b162019ba404a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}